---
title: "PlayingWithData"
author: "Colleen Minnihan"
date: "3/29/2021"
output: html_document
---

```{r message = FALSE, warning = FALSE}
# load libraries 
library(fivethirtyeight)
library(dplyr)
library(tidytext)
library(tidyr)
library(tidyverse)
library(ggplot2)
# for word cloud
library(textdata)
library(reshape2)
library(wordcloud)
```

```{r}
# read in data sets
troll_tweets_news <- read.csv("IRAhandle_tweets_12.csv") %>%
  select(-alt_external_id,-external_author_id)
  #seems to be imitating news sources
troll_tweets_left <- read.csv("IRAhandle_tweets_5.csv") %>%
  select(-alt_external_id,-external_author_id) #seems to be imitating the far left
troll_tweets_right <- read.csv("IRAhandle_tweets_8.csv") %>%
  select(-alt_external_id,-external_author_id) #seems to be imitating Trump supporters


#combine datasets
troll_tweets_big <- troll_tweets_news %>% 
  bind_rows(troll_tweets_left) %>%
  bind_rows(troll_tweets_right)
```


```{r}
nlevels(factor(troll_tweets_right$author))
nlevels(factor(troll_tweets_left$author))
nlevels(factor(troll_tweets_left$author))


```

**Data Exploration: size, distribution, etc**

```{r}
# look at the distribution
dim(troll_tweets_news)
dim(troll_tweets_left)
dim(troll_tweets_right)
```

**Q: Data Cleaning**

```{r}
# only consider english data 
troll_tweets1 <- troll_tweets_news %>%
  filter(language == 'English') #only tweets that are in English
  
troll_tweets_left <- troll_tweets_left %>%
  filter(language == 'English')

troll_tweets_right <- troll_tweets_right %>%
  filter(language == 'English')

troll_tweets1
troll_tweets_left
troll_tweets_right
```

```{r}
troll_tweets1 %>% 
  select(where(is.numeric)) %>% 
  pivot_longer(cols = everything(),
               names_to = "variable", 
               values_to = "value") %>% 
  ggplot(aes(x = value)) +
  geom_bar() +
  facet_wrap(vars(variable), 
             scales = "free")
```


```{r}
#separate tweet so that each row gets an individual word: unnest tokens
troll_tweets_untoken <- troll_tweets1 %>%
  unnest_tokens(word,content)

troll_tweets_untoken

#get rid of stopwords (the, and, etc.)
troll_tweets_cleaned <- troll_tweets_untoken %>%
  anti_join(stop_words) %>%
  filter(word != 'https', word != 't.co') #get rid of https and t.co

# top 100 words 
troll_tweets_cleaned %>%
  count(word) %>%
  slice_max(order_by = n, n = 100)
```

```{r}
# Final cleaning stage: get rid of 2, rt, 1, amp, 3, http, 5, 4, 10, and single letter words
troll_tweets_fullclean <- troll_tweets_cleaned %>%
  mutate(word = str_extract(word,"[a-z']+")) %>%
  filter(word != '1', word != '2', word != '3', word != '4', word != '5', word != '10', word != 'rt', word != 'amp', word != 'http', !(word %in% letters))
```

```{r}
troll_tweets_small <- troll_tweets_fullclean %>%
  count(word) %>%
  slice_max(order_by = n, n = 50)

ggplot(troll_tweets_small, aes(y = fct_reorder(word,n), x = n)) +
  geom_col()
```

**Q: Make wordcloud**
```{r message = FALSE, warning = FALSE}
troll_tweets_100 <- troll_tweets_fullclean %>%
  count(word) %>%
  slice_max(order_by = n, n = 100)

# most frequently used words
troll_tweets_100 %>%
  with(wordcloud(word, n, max.words = 100))

wordcloud(words = troll_tweets_100$word, freq = troll_tweets_100$n, min.freq = 1,
          max.words=200, random.order=FALSE, rot.per=0.35, 
          colors=brewer.pal(8, "Dark2"))


# sentiment analysis (positive vs negative)
troll_tweets_fullclean %>%
  inner_join(get_sentiments("bing")) %>%
  count(word, sentiment, sort = TRUE) %>%
  acast(word ~ sentiment, value.var = "n", fill = 0) %>%
  comparison.cloud(colors = c("red", "green"),
                   max.words = 100)

```

**Q: More Sentiment Analysis**

```{r}
# bing makes it into positive / negative
troll_tweets_sentiment <- troll_tweets_fullclean %>%
  inner_join(get_sentiments("bing")) %>%
  count(sentiment)

#count negative and positive words
troll_tweets_sentiment

get_sentiments("bing")
```




